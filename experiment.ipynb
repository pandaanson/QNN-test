{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1/50\n",
      "in function [0.5, 0.5, 0.375, 0.625, 0.25, 0.75, 0.125, 0.875, 0.0]\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 201\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m    200\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ansonkong/Downloads/QNN-test/p122_synthetic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Load your data\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[43mrun_multiple_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/ansonkong/Downloads/QNN-test/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mrun_multiple_experiments\u001b[0;34m(data, target_column, feature_column, save_path, num_runs, number_of_quantile_one_end)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_runs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Assuming QNNs_gen is a function you have defined elsewhere that computes some results\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mQNNs_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_quantile_one_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculating quantiles\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# For the bottom quantile from 0 to 0.5 divided by 'number_of_quantile_one_end'\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 162\u001b[0m, in \u001b[0;36mQNNs_gen\u001b[0;34m(data, target_column, feature_column, save_path, number_of_quantile_one_end)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Adjusted quantile loss calculation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     loss \u001b[38;5;241m=\u001b[39m adjusted_quantile_loss(outputs, labels, quantile, lower_bound, upper_bound)\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Only retain graph on the first backward pass\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Ensure subsequent passes do not retain graph\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m optimizers:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_multiple_experiments(data, target_column, feature_column, save_path, num_runs=50, number_of_quantile_one_end=4):\n",
    "    results = []\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Starting run {run + 1}/{num_runs}\")\n",
    "        # Assuming QNNs_gen is a function you have defined elsewhere that computes some results\n",
    "        result = QNNs_gen(data, target_column, feature_column, save_path, number_of_quantile_one_end)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Calculating quantiles\n",
    "    # For the bottom quantile from 0 to 0.5 divided by 'number_of_quantile_one_end'\n",
    "    bottom_quantile = [i / (number_of_quantile_one_end * 2) for i in range(number_of_quantile_one_end)]\n",
    "    # For the top quantile from 0.5 to 1 divided by 'number_of_quantile_one_end'\n",
    "    top_quantile = [0.5 + i / (number_of_quantile_one_end * 2) for i in range(number_of_quantile_one_end)]\n",
    "    \n",
    "    # Sort bottom quantile in descending order\n",
    "    bottom_quantile = sorted(bottom_quantile, reverse=True)\n",
    "    # Sort top quantile in ascending order (it's already ascending but included for clarity)\n",
    "    top_quantile = sorted(top_quantile)\n",
    "\n",
    "    # Combine quantiles starting from 0.5 and interleaving top and bottom quantiles\n",
    "    quantiles = [0.5]\n",
    "    for t, b in zip(top_quantile, bottom_quantile):\n",
    "        quantiles.append(t)\n",
    "        quantiles.append(b)\n",
    "    \n",
    "    # Create a DataFrame from the results with appropriate quantile columns\n",
    "    print(f'in csv {quantiles}')\n",
    "    df = pd.DataFrame(results, columns=quantiles)\n",
    "    df.to_csv(f\"{save_path}quantile_performance_numberofquantile{number_of_quantile_one_end*2 + 1}.csv\", index=False)\n",
    "    print(\"All runs completed and results saved to CSV.\")\n",
    "\n",
    "def QNNs_gen(data,target_column,feature_column,save_path,number_of_quantile_one_end):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score\n",
    "    import joblib\n",
    "    class NeuralNet(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(NeuralNet, self).__init__()\n",
    "            self.layer1 = nn.Linear(input_size, 128)\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.layer2 = nn.Linear(128, 64)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.layer3 = nn.Linear(64, 32)\n",
    "            self.relu3 = nn.ReLU()\n",
    "            self.output_layer = nn.Linear(32, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Forward pass records for optimization\n",
    "            self.outputs = {}\n",
    "            self.activations = {}\n",
    "\n",
    "            z1 = self.layer1(x)\n",
    "            self.activations['layer1'] = z1\n",
    "            x = self.relu1(z1)\n",
    "\n",
    "            z2 = self.layer2(x)\n",
    "            self.activations['layer2'] = z2\n",
    "            x = self.relu2(z2)\n",
    "\n",
    "            z3 = self.layer3(x)\n",
    "            self.activations['layer3'] = z3\n",
    "            x = self.relu3(z3)\n",
    "\n",
    "            out = self.output_layer(x)\n",
    "            self.outputs['output'] = out\n",
    "            return out\n",
    "    def adjusted_quantile_loss(outputs, targets, quantile, lower_bound=None, upper_bound=None):\n",
    "        errors = targets - outputs\n",
    "        basic_loss = torch.max((quantile - 1) * errors, quantile * errors)\n",
    "        loss = torch.mean(basic_loss)\n",
    "\n",
    "        if lower_bound is not None:\n",
    "            crossing_penalty = torch.mean(torch.relu(lower_bound - outputs))\n",
    "            loss += crossing_penalty\n",
    "        if upper_bound is not None:\n",
    "            crossing_penalty = torch.mean(torch.relu(outputs - upper_bound))\n",
    "            loss += crossing_penalty\n",
    "\n",
    "        return loss\n",
    "    features = data[feature_column]\n",
    "    target = data[target_column]\n",
    "    X = torch.tensor(features.values, dtype=torch.float32)\n",
    "    y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "    X_test = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # For the bottom quantile from 0 to 0.5 divided by 'number_of_quantile_one_end'\n",
    "    bottom_quantiles = [i / (number_of_quantile_one_end * 2) for i in range(number_of_quantile_one_end)]\n",
    "    # For the top quantile from 0.5 to 1 divided by 'number_of_quantile_one_end'\n",
    "    top_quantiles = [0.5 + i / (number_of_quantile_one_end * 2) for i in range(number_of_quantile_one_end)]\n",
    "    # Sort bottom quantile in descending order\n",
    "    bottom_quantiles = sorted(bottom_quantiles, reverse=True)\n",
    "    # Sort top quantile in ascending order (it's already ascending but included for clarity)\n",
    "    top_quantiles = sorted(top_quantiles)\n",
    "\n",
    "    # Combine quantiles starting from 0.5 and interleaving top and bottom quantiles\n",
    "    quantiles = [0.5]\n",
    "    for t, b in zip(top_quantiles, bottom_quantiles):\n",
    "        quantiles.append(t)\n",
    "        quantiles.append(b)\n",
    "    models = [NeuralNet(X_train.shape[1], 1) for _ in quantiles]\n",
    "    optimizers = [optim.Adam(model.parameters(), lr=0.01) for model in models]\n",
    "\n",
    "    # Store bounds for each quantile and input\n",
    "    input_bounds = {q: {'lower': None, 'upper': None} for q in quantiles}\n",
    "\n",
    "\n",
    "\n",
    "    # Adjusted training loop\n",
    "    print(print(f'in function {quantiles}'))\n",
    "    for epoch in range(200):\n",
    "        for inputs, labels in train_loader:\n",
    "            current_outputs = {}  # Dictionary to store outputs for current batch\n",
    "\n",
    "            # Clear gradients at the start of each batch\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            first_pass = True  # Flag to handle retain_graph properly\n",
    "\n",
    "            for q_idx, quantile in enumerate(quantiles):\n",
    "                model = models[q_idx]\n",
    "                outputs = model(inputs)\n",
    "                current_outputs[quantile] = outputs.detach().clone()  # Detach and clone to avoid in-place modifications\n",
    "                def set_bounds(top_quantiles, bottom_quantiles, current_outputs, quantile):\n",
    "                    lower_bound = None\n",
    "                    upper_bound = None\n",
    "\n",
    "                    # Check if the quantile is in the top or bottom array\n",
    "                    if quantile in top_quantiles:\n",
    "                        # Find the index of the quantile in the top array\n",
    "                        index = top_quantiles.index(quantile)\n",
    "                        # Set lower bound from the previous quantile or 0.5 if it is the first quantile in the array\n",
    "                        lower_bound = current_outputs.get(top_quantiles[index - 1] if index > 0 else 0.5)\n",
    "\n",
    "                    elif quantile in bottom_quantiles:\n",
    "                        # Find the index of the quantile in the bottom array\n",
    "                        index = bottom_quantiles.index(quantile)\n",
    "                        # Set upper bound from the previous quantile or 0.5 if it is the first quantile in the array\n",
    "                        upper_bound = current_outputs.get(bottom_quantiles[index - 1] if index > 0 else 0.5)\n",
    "\n",
    "                    return lower_bound, upper_bound\n",
    "\n",
    "                lower_bound, upper_bound=set_bounds(top_quantiles, bottom_quantiles, current_outputs, quantile)\n",
    "\n",
    "                # Adjusted quantile loss calculation\n",
    "                loss = adjusted_quantile_loss(outputs, labels, quantile, lower_bound, upper_bound)\n",
    "                loss.backward(retain_graph=first_pass)  # Only retain graph on the first backward pass\n",
    "\n",
    "                first_pass = False  # Ensure subsequent passes do not retain graph\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.step()\n",
    "\n",
    "            # Optionally, clear dictionary to free memory after processing each batch\n",
    "            current_outputs.clear()\n",
    "    # Evaluation of models\n",
    "    all_rquare=[]\n",
    "    for i, model in enumerate(models):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions_train = model(X_train)\n",
    "            predictions_test = model(X_test)\n",
    "            r2_train = r2_score(y_train.numpy(), predictions_train.numpy())\n",
    "            r2_test = r2_score(y_test.numpy(), predictions_test.numpy())\n",
    "            all_rquare.append(r2_test)\n",
    "            print(f'Quantile: {quantiles[i]}, Training R-squared: {r2_train:.4f}, Testing R-squared: {r2_test:.4f}')\n",
    "    # After training all models, save each model's state\n",
    "    joblib.dump(scaler, f'{save_path}scaler.pkl')\n",
    "    for idx, model in enumerate(models):\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'weights': [param.detach().numpy() for param in model.parameters()]\n",
    "        }, f'{save_path}model_quantile_{quantiles[idx]}.pth')\n",
    "    print(f'R sqaures {all_rquare}')\n",
    "    \n",
    "\n",
    "    return all_rquare\n",
    "file_path = '/Users/ansonkong/Downloads/QNN-test/p122_synthetic.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "#Feature\n",
    "feature_column=['battery_2#p122','gas-cc#p122','upv#p122','wind-ons#p122']\n",
    "#target\n",
    "target_column='value'\n",
    "save_path=\"/Users/ansonkong/Downloads/QNN-test/\"\n",
    "# Example usage\n",
    "data = pd.read_csv('/Users/ansonkong/Downloads/QNN-test/p122_synthetic.csv')  # Load your data\n",
    "run_multiple_experiments(data, target_column, feature_column, '/Users/ansonkong/Downloads/QNN-test/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
