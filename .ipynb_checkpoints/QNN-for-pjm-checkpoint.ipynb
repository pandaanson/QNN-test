{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/ansonkong/Desktop/pjm_east_2024_synthetic.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature target split\n",
    "target = data['value']\n",
    "features = data.drop('value', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Good old train test split\n",
    "# Convert features and target to tensors\n",
    "X = torch.tensor(features.values, dtype=torch.float32)\n",
    "y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)  # Ensure y is the correct shape\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the scaler on your TRAINING data only\n",
    "X_train = scaler.fit_transform(X_train.numpy())  # Convert to NumPy array to fit\n",
    "X_test = scaler.transform(X_test.numpy())  # Apply the same transform to the test data\n",
    "\n",
    "# Convert scaled features back to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting notebook\n",
      "  Downloading notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.0 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting qtconsole\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipykernel\n",
      "  Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 60.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 43.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert\n",
      "  Downloading nbconvert-7.16.3-py3-none-any.whl (257 kB)\n",
      "\u001b[K     |████████████████████████████████| 257 kB 59.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq>=24\n",
      "  Downloading pyzmq-25.1.2-cp39-cp39-macosx_10_15_universal2.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 73.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 81.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 36.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil\n",
      "  Downloading psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl (248 kB)\n",
      "\u001b[K     |████████████████████████████████| 248 kB 74.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting debugpy>=1.6.5\n",
      "  Downloading debugpy-1.8.1-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 63.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Collecting appnope\n",
      "  Downloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting traitlets>=5.4.0\n",
      "  Downloading traitlets-5.14.2-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 95.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting comm>=0.1.1\n",
      "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting tornado>=6.1\n",
      "  Downloading tornado-6.4-cp38-abi3-macosx_10_9_x86_64.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 116.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython>=7.23.1\n",
      "  Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "\u001b[K     |████████████████████████████████| 808 kB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 66.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
      "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "\u001b[K     |████████████████████████████████| 386 kB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pexpect>4.3\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 77.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting pygments>=2.4.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 48.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 38.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.8.3\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 71.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=0.5\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting platformdirs>=2.5\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=4.0.10\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 38.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach!=5.0.0\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 50.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 24.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mistune<4,>=2.0.3\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 69.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tinycss2\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting markupsafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jinja2>=3.0\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 70.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Collecting nbformat>=5.7\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 54.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting fastjsonschema>=2.15\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Collecting jsonschema>=2.6\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 52.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 82.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.18.0-cp39-cp39-macosx_10_12_x86_64.whl (336 kB)\n",
      "\u001b[K     |████████████████████████████████| 336 kB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Downloading jupyter_server-2.14.0-py3-none-any.whl (383 kB)\n",
      "\u001b[K     |████████████████████████████████| 383 kB 23.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab<4.2,>=4.1.1\n",
      "  Downloading jupyterlab-4.1.6-py3-none-any.whl (11.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.4 MB 123.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting notebook-shim<0.3,>=0.2\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1\n",
      "  Downloading jupyterlab_server-2.26.0-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-events>=0.9.0\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Collecting websocket-client>=1.7\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 81.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting terminado>=0.8.3\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client>=0.9\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 51.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting send2trash>=1.8.2\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Collecting anyio>=3.1.0\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 112.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting overrides>=5.0\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting argon2-cffi>=21.1\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 86.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 48.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-json-logger>=2.0.4\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Collecting rfc3986-validator>=0.1.1\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting uri-template\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting fqdn\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting isoduration\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting webcolors>=1.11\n",
      "  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting jupyter-lsp>=2.0.0\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 36.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tomli>=1.2.2\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting httpx>=0.25.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 59.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-lru>=1.0.0\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 33.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 73.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 77.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.31\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 67.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting babel>=2.10\n",
      "  Downloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 43.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting json5>=0.9.0\n",
      "  Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl (122 kB)\n",
      "\u001b[K     |████████████████████████████████| 122 kB 84.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 46.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cffi>=1.0.1\n",
      "  Downloading cffi-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 37.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 25.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting arrow>=0.15.0\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting types-python-dateutil>=2.8.10\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: rpds-py, attrs, six, referencing, zipp, types-python-dateutil, traitlets, python-dateutil, platformdirs, jsonschema-specifications, tornado, pyzmq, pycparser, jupyter-core, jsonschema, importlib-metadata, fastjsonschema, arrow, webencodings, webcolors, uri-template, soupsieve, rfc3986-validator, rfc3339-validator, ptyprocess, nbformat, markupsafe, jupyter-client, jsonpointer, isoduration, idna, fqdn, cffi, wcwidth, typing-extensions, tinycss2, terminado, sniffio, pyyaml, python-json-logger, pygments, pure-eval, parso, pandocfilters, packaging, nbclient, mistune, jupyterlab-pygments, jinja2, executing, exceptiongroup, defusedxml, bleach, beautifulsoup4, asttokens, argon2-cffi-bindings, websocket-client, urllib3, stack-data, send2trash, prompt-toolkit, prometheus-client, pexpect, overrides, nbconvert, matplotlib-inline, jupyter-server-terminals, jupyter-events, jedi, h11, decorator, charset-normalizer, certifi, argon2-cffi, anyio, requests, psutil, nest-asyncio, jupyter-server, json5, ipython, httpcore, debugpy, comm, babel, appnope, tomli, notebook-shim, jupyterlab-server, jupyter-lsp, ipykernel, httpx, async-lru, widgetsnbextension, qtpy, jupyterlab-widgets, jupyterlab, qtconsole, notebook, jupyter-console, ipywidgets, jupyter\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.7.0\n",
      "    Uninstalling zipp-3.7.0:\n",
      "      Successfully uninstalled zipp-3.7.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 2.5.4\n",
      "    Uninstalling platformdirs-2.5.4:\n",
      "      Successfully uninstalled platformdirs-2.5.4\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.1\n",
      "    Uninstalling tornado-6.1:\n",
      "      Successfully uninstalled tornado-6.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 22.3.0\n",
      "    Uninstalling pyzmq-22.3.0:\n",
      "      Successfully uninstalled pyzmq-22.3.0\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.21\n",
      "    Uninstalling pycparser-2.21:\n",
      "      Successfully uninstalled pycparser-2.21\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.9.2\n",
      "    Uninstalling jupyter-core-4.9.2:\n",
      "      Successfully uninstalled jupyter-core-4.9.2\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.4.0\n",
      "    Uninstalling jsonschema-4.4.0:\n",
      "      Successfully uninstalled jsonschema-4.4.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "  Attempting uninstall: fastjsonschema\n",
      "    Found existing installation: fastjsonschema 2.15.1\n",
      "    Uninstalling fastjsonschema-2.15.1:\n",
      "      Successfully uninstalled fastjsonschema-2.15.1\n",
      "  Attempting uninstall: arrow\n",
      "    Found existing installation: arrow 1.2.2\n",
      "    Uninstalling arrow-1.2.2:\n",
      "      Successfully uninstalled arrow-1.2.2\n",
      "  Attempting uninstall: webencodings\n",
      "    Found existing installation: webencodings 0.5.1\n",
      "    Uninstalling webencodings-0.5.1:\n",
      "      Successfully uninstalled webencodings-0.5.1\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.3.1\n",
      "    Uninstalling soupsieve-2.3.1:\n",
      "      Successfully uninstalled soupsieve-2.3.1\n",
      "  Attempting uninstall: ptyprocess\n",
      "    Found existing installation: ptyprocess 0.7.0\n",
      "    Uninstalling ptyprocess-0.7.0:\n",
      "      Successfully uninstalled ptyprocess-0.7.0\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.3.0\n",
      "    Uninstalling nbformat-5.3.0:\n",
      "      Successfully uninstalled nbformat-5.3.0\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.12\n",
      "    Uninstalling jupyter-client-6.1.12:\n",
      "      Successfully uninstalled jupyter-client-6.1.12\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.15.0\n",
      "    Uninstalling cffi-1.15.0:\n",
      "      Successfully uninstalled cffi-1.15.0\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.10.0\n",
      "    Uninstalling typing-extensions-4.10.0:\n",
      "      Successfully uninstalled typing-extensions-4.10.0\n",
      "  Attempting uninstall: terminado\n",
      "    Found existing installation: terminado 0.13.1\n",
      "    Uninstalling terminado-0.13.1:\n",
      "      Successfully uninstalled terminado-0.13.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: pure-eval\n",
      "    Found existing installation: pure-eval 0.2.2\n",
      "    Uninstalling pure-eval-0.2.2:\n",
      "      Successfully uninstalled pure-eval-0.2.2\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.3\n",
      "    Uninstalling parso-0.8.3:\n",
      "      Successfully uninstalled parso-0.8.3\n",
      "  Attempting uninstall: pandocfilters\n",
      "    Found existing installation: pandocfilters 1.5.0\n",
      "    Uninstalling pandocfilters-1.5.0:\n",
      "      Successfully uninstalled pandocfilters-1.5.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.13\n",
      "    Uninstalling nbclient-0.5.13:\n",
      "      Successfully uninstalled nbclient-0.5.13\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: jupyterlab-pygments\n",
      "    Found existing installation: jupyterlab-pygments 0.1.2\n",
      "    Uninstalling jupyterlab-pygments-0.1.2:\n",
      "      Successfully uninstalled jupyterlab-pygments-0.1.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 0.8.3\n",
      "    Uninstalling executing-0.8.3:\n",
      "      Successfully uninstalled executing-0.8.3\n",
      "  Attempting uninstall: defusedxml\n",
      "    Found existing installation: defusedxml 0.7.1\n",
      "    Uninstalling defusedxml-0.7.1:\n",
      "      Successfully uninstalled defusedxml-0.7.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 4.1.0\n",
      "    Uninstalling bleach-4.1.0:\n",
      "      Successfully uninstalled bleach-4.1.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 2.0.5\n",
      "    Uninstalling asttokens-2.0.5:\n",
      "      Successfully uninstalled asttokens-2.0.5\n",
      "  Attempting uninstall: argon2-cffi-bindings\n",
      "    Found existing installation: argon2-cffi-bindings 21.2.0\n",
      "    Uninstalling argon2-cffi-bindings-21.2.0:\n",
      "      Successfully uninstalled argon2-cffi-bindings-21.2.0\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Uninstalling websocket-client-0.58.0:\n",
      "      Successfully uninstalled websocket-client-0.58.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.12\n",
      "    Uninstalling urllib3-1.26.12:\n",
      "      Successfully uninstalled urllib3-1.26.12\n",
      "  Attempting uninstall: stack-data\n",
      "    Found existing installation: stack-data 0.2.0\n",
      "    Uninstalling stack-data-0.2.0:\n",
      "      Successfully uninstalled stack-data-0.2.0\n",
      "  Attempting uninstall: send2trash\n",
      "    Found existing installation: Send2Trash 1.8.0\n",
      "    Uninstalling Send2Trash-1.8.0:\n",
      "      Successfully uninstalled Send2Trash-1.8.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.28\n",
      "    Uninstalling prompt-toolkit-3.0.28:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.28\n",
      "  Attempting uninstall: prometheus-client\n",
      "    Found existing installation: prometheus-client 0.13.1\n",
      "    Uninstalling prometheus-client-0.13.1:\n",
      "      Successfully uninstalled prometheus-client-0.13.1\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.8.0\n",
      "    Uninstalling pexpect-4.8.0:\n",
      "      Successfully uninstalled pexpect-4.8.0\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.4.4\n",
      "    Uninstalling nbconvert-6.4.4:\n",
      "      Successfully uninstalled nbconvert-6.4.4\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.2\n",
      "    Uninstalling matplotlib-inline-0.1.2:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.2\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.18.1\n",
      "    Uninstalling jedi-0.18.1:\n",
      "      Successfully uninstalled jedi-0.18.1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.12\n",
      "    Uninstalling charset-normalizer-2.0.12:\n",
      "      Successfully uninstalled charset-normalizer-2.0.12\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "  Attempting uninstall: argon2-cffi\n",
      "    Found existing installation: argon2-cffi 21.3.0\n",
      "    Uninstalling argon2-cffi-21.3.0:\n",
      "      Successfully uninstalled argon2-cffi-21.3.0\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.5.0\n",
      "    Uninstalling anyio-3.5.0:\n",
      "      Successfully uninstalled anyio-3.5.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.8.0\n",
      "    Uninstalling psutil-5.8.0:\n",
      "      Successfully uninstalled psutil-5.8.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.5\n",
      "    Uninstalling nest-asyncio-1.5.5:\n",
      "      Successfully uninstalled nest-asyncio-1.5.5\n",
      "  Attempting uninstall: jupyter-server\n",
      "    Found existing installation: jupyter-server 1.13.5\n",
      "    Uninstalling jupyter-server-1.13.5:\n",
      "      Successfully uninstalled jupyter-server-1.13.5\n",
      "  Attempting uninstall: json5\n",
      "    Found existing installation: json5 0.9.6\n",
      "    Uninstalling json5-0.9.6:\n",
      "      Successfully uninstalled json5-0.9.6\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.2.0\n",
      "    Uninstalling ipython-8.2.0:\n",
      "      Successfully uninstalled ipython-8.2.0\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.5.1\n",
      "    Uninstalling debugpy-1.5.1:\n",
      "      Successfully uninstalled debugpy-1.5.1\n",
      "  Attempting uninstall: babel\n",
      "    Found existing installation: Babel 2.9.1\n",
      "    Uninstalling Babel-2.9.1:\n",
      "      Successfully uninstalled Babel-2.9.1\n",
      "  Attempting uninstall: appnope\n",
      "    Found existing installation: appnope 0.1.2\n",
      "    Uninstalling appnope-0.1.2:\n",
      "      Successfully uninstalled appnope-0.1.2\n",
      "  Attempting uninstall: tomli\n",
      "    Found existing installation: tomli 1.2.2\n",
      "    Uninstalling tomli-1.2.2:\n",
      "      Successfully uninstalled tomli-1.2.2\n",
      "  Attempting uninstall: jupyterlab-server\n",
      "    Found existing installation: jupyterlab-server 2.10.3\n",
      "    Uninstalling jupyterlab-server-2.10.3:\n",
      "      Successfully uninstalled jupyterlab-server-2.10.3\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.9.1\n",
      "    Uninstalling ipykernel-6.9.1:\n",
      "      Successfully uninstalled ipykernel-6.9.1\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.5.2\n",
      "    Uninstalling widgetsnbextension-3.5.2:\n",
      "      Successfully uninstalled widgetsnbextension-3.5.2\n",
      "  Attempting uninstall: qtpy\n",
      "    Found existing installation: QtPy 2.0.1\n",
      "    Uninstalling QtPy-2.0.1:\n",
      "      Successfully uninstalled QtPy-2.0.1\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab-widgets 1.0.0\n",
      "    Uninstalling jupyterlab-widgets-1.0.0:\n",
      "      Successfully uninstalled jupyterlab-widgets-1.0.0\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 3.3.2\n",
      "    Uninstalling jupyterlab-3.3.2:\n",
      "      Successfully uninstalled jupyterlab-3.3.2\n",
      "  Attempting uninstall: qtconsole\n",
      "    Found existing installation: qtconsole 5.3.0\n",
      "    Uninstalling qtconsole-5.3.0:\n",
      "      Successfully uninstalled qtconsole-5.3.0\n",
      "  Attempting uninstall: notebook\n",
      "    Found existing installation: notebook 6.4.8\n",
      "    Uninstalling notebook-6.4.8:\n",
      "      Successfully uninstalled notebook-6.4.8\n",
      "  Attempting uninstall: jupyter-console\n",
      "    Found existing installation: jupyter-console 6.4.0\n",
      "    Uninstalling jupyter-console-6.4.0:\n",
      "      Successfully uninstalled jupyter-console-6.4.0\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.6.5\n",
      "    Uninstalling ipywidgets-7.6.5:\n",
      "      Successfully uninstalled ipywidgets-7.6.5\n",
      "  Attempting uninstall: jupyter\n",
      "    Found existing installation: jupyter 1.0.0\n",
      "    Uninstalling jupyter-1.0.0:\n",
      "      Successfully uninstalled jupyter-1.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "virtualenv 20.16.7 requires platformdirs<3,>=2.4, but you have platformdirs 4.2.0 which is incompatible.\n",
      "spyder 5.1.5 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.1 which is incompatible.\n",
      "spyder-kernels 2.1.3 requires jupyter-client<7,>=5.3.4, but you have jupyter-client 8.6.1 which is incompatible.\n",
      "python-lsp-server 1.2.4 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.1 which is incompatible.\n",
      "nbclassic 0.3.5 requires jupyter-server~=1.8, but you have jupyter-server 2.14.0 which is incompatible.\n",
      "nbclassic 0.3.5 requires notebook<7, but you have notebook 7.1.2 which is incompatible.\n",
      "botocore 1.24.32 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n",
      "awscli 2.11.5 requires cryptography<39.0.3,>=3.3.2, but you have cryptography 42.0.3 which is incompatible.\n",
      "awscli 2.11.5 requires prompt-toolkit<3.0.29,>=3.0.24, but you have prompt-toolkit 3.0.43 which is incompatible.\n",
      "awscli 2.11.5 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n",
      "aiohttp 3.8.1 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.3.2 which is incompatible.\u001b[0m\n",
      "Successfully installed anyio-4.3.0 appnope-0.1.4 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-2.4.1 async-lru-2.0.4 attrs-23.2.0 babel-2.14.0 beautifulsoup4-4.12.3 bleach-6.1.0 certifi-2024.2.2 cffi-1.16.0 charset-normalizer-3.3.2 comm-0.2.2 debugpy-1.8.1 decorator-5.1.1 defusedxml-0.7.1 exceptiongroup-1.2.0 executing-2.0.1 fastjsonschema-2.19.1 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 importlib-metadata-7.1.0 ipykernel-6.29.4 ipython-8.18.1 ipywidgets-8.1.2 isoduration-20.11.0 jedi-0.19.1 jinja2-3.1.3 json5-0.9.25 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-client-8.6.1 jupyter-console-6.6.3 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.0 jupyter-server-terminals-0.5.3 jupyterlab-4.1.6 jupyterlab-pygments-0.3.0 jupyterlab-server-2.26.0 jupyterlab-widgets-3.0.10 markupsafe-2.1.5 matplotlib-inline-0.1.6 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.3 nbformat-5.10.4 nest-asyncio-1.6.0 notebook-7.1.2 notebook-shim-0.2.4 overrides-7.7.0 packaging-24.0 pandocfilters-1.5.1 parso-0.8.4 pexpect-4.9.0 platformdirs-4.2.0 prometheus-client-0.20.0 prompt-toolkit-3.0.43 psutil-5.9.8 ptyprocess-0.7.0 pure-eval-0.2.2 pycparser-2.22 pygments-2.17.2 python-dateutil-2.9.0.post0 python-json-logger-2.0.7 pyyaml-6.0.1 pyzmq-25.1.2 qtconsole-5.5.1 qtpy-2.4.1 referencing-0.34.0 requests-2.31.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.18.0 send2trash-1.8.3 six-1.16.0 sniffio-1.3.1 soupsieve-2.5 stack-data-0.6.3 terminado-0.18.1 tinycss2-1.2.1 tomli-2.0.1 tornado-6.4 traitlets-5.14.2 types-python-dateutil-2.9.0.20240316 typing-extensions-4.11.0 uri-template-1.3.0 urllib3-2.2.1 wcwidth-0.2.13 webcolors-1.13 webencodings-0.5.1 websocket-client-1.7.0 widgetsnbextension-4.0.10 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall --no-cache-dir jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class QuantileNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_quantiles):\n",
    "        super(QuantileNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_quantiles)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def quantile_loss(preds, target, quantiles):\n",
    "    assert len(quantiles) == preds.shape[1], \"Quantiles size must match predictions width.\"\n",
    "    errors = target.unsqueeze(1) - preds\n",
    "    return torch.max((quantiles - 1) * errors, quantiles * errors).mean()\n",
    "\n",
    "# Initialize the model\n",
    "num_features = X_train.shape[1]\n",
    "num_quantiles = 50\n",
    "quantiles = torch.linspace(0.01, 0.99, steps=num_quantiles)\n",
    "model = QuantileNetwork(input_size=num_features, num_quantiles=num_quantiles)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch_x)\n",
    "        loss = quantile_loss(preds, batch_y, quantiles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "num_features = X_train.shape[1]\n",
    "num_quantiles = 50\n",
    "quantiles = torch.linspace(0.01, 0.99, steps=num_quantiles)\n",
    "def quantile_loss(preds, target, quantiles):\n",
    "    assert len(quantiles) == preds.shape[1], \"Quantiles size must match predictions width.\"\n",
    "    errors = target.unsqueeze(1) - preds\n",
    "    return torch.max((quantiles - 1) * errors, quantiles * errors).mean()\n",
    "# Define Quantile Network with three hidden layers\n",
    "class QuantileNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes, dropout_rate):\n",
    "        super(QuantileNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))  # Output layer\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Train and evaluate model\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, quantiles, epochs=2000):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = quantile_loss(output, target, quantiles)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model(data)\n",
    "            loss = quantile_loss(output, target, quantiles)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# Hyperparameter search space adjustments\n",
    "neurons_options = [\n",
    "    (32, 64, 128),\n",
    "    (64, 128, 256),\n",
    "    (128, 256, 512)\n",
    "]\n",
    "batch_sizes = [128, 512]#[64, 128, 256, 512]\n",
    "neurons = [32, 64, 128, 256]\n",
    "optimizers_dict = {'Adam': optim.Adam, 'Adagrad': optim.Adagrad, 'RMSprop': optim.RMSprop}\n",
    "dropout_rates = np.linspace(0, 0.3, num=4)\n",
    "learning_rates = np.logspace(-5, -1, num=5)\n",
    "# Calculate the total number of iterations\n",
    "total_iterations = len(batch_sizes) * len(neurons_options) * len(dropout_rates) * len(optimizers_dict) * len(learning_rates)\n",
    "current_iteration = 0\n",
    "# Hyperparameter search\n",
    "best_loss = np.inf\n",
    "best_config = None\n",
    "best_model=None\n",
    "for batch_size in batch_sizes:\n",
    "    for hidden_sizes in neurons_options:  # Corrected from neurons to neurons_options\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for optimizer_name, optimizer_class in optimizers_dict.items():\n",
    "                for lr in learning_rates:\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    # Correct instantiation with the actual input size\n",
    "                    model = QuantileNetwork(input_size=85, output_size=50, hidden_sizes=hidden_sizes, dropout_rate=dropout_rate)\n",
    "                    optimizer = optimizer_class(model.parameters(), lr=lr)  # Corrected from opt to optimizer\n",
    "                    loss = train_and_evaluate(model, train_loader, val_loader, optimizer, quantiles, epochs=100)  # Specified epochs for clarity\n",
    "                    if loss < best_loss:\n",
    "                        best_loss = loss\n",
    "                        best_config = (batch_size, hidden_sizes, dropout_rate, optimizer_name, lr)\n",
    "                        best_model = model\n",
    "                        print(f\"Best Configuration So far: {best_config} with Loss: {best_loss}\")\n",
    "                        print(f\"Search done for {batch_size},{hidden_sizes},{dropout_rate},{optimizer_name},{lr}\")\n",
    "                    current_iteration += 1\n",
    "                    completion_percentage = (current_iteration / total_iterations) * 100\n",
    "                    print(f\"Completed: {completion_percentage:.2f}%\")\n",
    "\n",
    "print(f\"Best Configuration: {best_config} with Loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
