{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Initialize the Simulation Environment\n",
    "First, let's set up the basic parameters for our simulation, including the number of cities, scenarios, and the structure for trends and shocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "num_cities = 3\n",
    "num_scenarios = 100\n",
    "\n",
    "# Initialize arrays to hold the demand for each city across scenarios\n",
    "demand = np.zeros((num_scenarios, num_cities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Simulate Trends and Shocks\n",
    "For each city, we'll simulate both a general trend (which could be positive or negative, reflecting economic growth or decline) and random shocks that could represent unexpected events affecting supply and demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trends - Let's assume a simple linear trend for simplicity, which can vary across cities\n",
    "trend_strengths = np.random.uniform(-0.02, 0.02, num_cities)  # Some cities might grow, others might decline\n",
    "\n",
    "# Shocks - Random events affecting each city, with occasional major shocks\n",
    "shock_strength = 0.1  # Standard deviation of normal shocks\n",
    "major_shock_strength = 0.5  # Magnitude of major shocks\n",
    "major_shock_prob = 0.1  # Probability of a major shock in any scenario\n",
    "\n",
    "for city in range(num_cities):\n",
    "    # Apply the trend for each city\n",
    "    demand[:, city] += np.linspace(0, trend_strengths[city]*num_scenarios, num_scenarios)\n",
    "    \n",
    "    # Apply normal shocks\n",
    "    demand[:, city] += np.random.normal(0, shock_strength, num_scenarios)\n",
    "    \n",
    "    # Apply major shocks sporadically\n",
    "    for scenario in range(num_scenarios):\n",
    "        if np.random.rand() < major_shock_prob:\n",
    "            demand[scenario, city] += np.random.normal(0, major_shock_strength)\n",
    "\n",
    "# Apply covariance between cities' demands to simulate economic linkage\n",
    "cov_matrix = np.array([[1.0, 0.5, 0.3],\n",
    "                       [0.5, 1.0, 0.4],\n",
    "                       [0.3, 0.4, 1.0]])  # Simplified example covariance matrix\n",
    "cholesky_decomp = np.linalg.cholesky(cov_matrix)\n",
    "\n",
    "demand = demand.dot(cholesky_decomp.T)  # Applying covariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Demand and Supply Adjustment Based on Linkages\n",
    "Now, let's assume some basic economic linkages between the cities. For instance, excess demand in one city can be partially met by surplus supply in another, depending on the strength of their economic ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = np.array([[1.0, 0.2, 0.1],\n",
    "                           [0.2, 1.0, 0.3],\n",
    "                           [0.1, 0.3, 1.0]])  # Example linkage matrix indicating how cities can influence each other\n",
    "\n",
    "# Adjust demand based on linkages (simplified model)\n",
    "for scenario in range(num_scenarios):\n",
    "    for city in range(num_cities):\n",
    "        # Calculate adjustment based on other cities' surplus/deficit\n",
    "        adjustment = sum(linkage_matrix[city, other_city] * (demand[scenario, other_city] - demand[scenario, city])\n",
    "                         for other_city in range(num_cities) if other_city != city)\n",
    "        demand[scenario, city] += adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To construct a simulation that involves optimizing capital endowment and production decisions in a two-stage stochastic optimization framework for a company operating in three cities, we'll follow these steps closely:\n",
    "\n",
    "Define the Supply Function for each city, dependent on capital endowment and operational decisions.\n",
    "Stage 1: Prioritize capital allocation to ensure production capabilities.\n",
    "Stage 2: Determine the optimal production level based on demand scenarios.\n",
    "Objective: Ensure demand can be met at least 95% of the time while maximizing profits.\n",
    "Since the detailed implementation of the algorithm from the provided paper is complex and would require specific knowledge from the paper itself, which we've discussed conceptually but haven't executed directly here, I'll outline a generalized approach based on common principles in two-stage stochastic optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Supply Function and Capital Endowment\n",
    "Let's define a simplified supply function where the production capacity and cost are functions of the capital endowment. We assume higher capital endowment increases production capacity but at a diminishing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supply(capital, production, city_index):\n",
    "    \"\"\"\n",
    "    Calculate the supply based on capital endowment and production decision.\n",
    "    city_index allows for city-specific parameters in the supply function.\n",
    "    \"\"\"\n",
    "    capacity = np.log1p(capital[city_index])  # Logarithmic growth of capacity with capital\n",
    "    cost_per_unit = 1 / (1 + np.log1p(capital[city_index]))  # Decreasing cost per unit with more capital\n",
    "    supply = min(capacity, production)\n",
    "    cost = production * cost_per_unit\n",
    "    return supply, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "\n",
    "capital_bounds = (0.1, 10)  # Bounds for capital investment decisions\n",
    "production_bounds = (0, np.inf)  # Production can range from 0 to an upper limit\n",
    "\n",
    "# Stage 1: Optimizing capital endowment to ensure flexibility in meeting demand\n",
    "# Simplified as a single optimization across all cities for illustration\n",
    "def stage1_objective(capital):\n",
    "    \"\"\"\n",
    "    Stage 1 objective: Minimize capital while ensuring potential to meet demand.\n",
    "    This is a placeholder and should be replaced with a more complex model.\n",
    "    \"\"\"\n",
    "    total_cost = sum(capital)  # Simplify: Minimize total capital endowment\n",
    "    return total_cost\n",
    "\n",
    "initial_capital = [1 for _ in range(num_cities)]  # Initial guess for capital endowment\n",
    "capital_opt = scipy.optimize.minimize(stage1_objective, initial_capital, bounds=[capital_bounds]*num_cities)\n",
    "\n",
    "# Stage 2: Given capital, optimize production for each scenario to maximize profit\n",
    "def stage2_objective(production, capital, demand_scenario):\n",
    "    \"\"\"\n",
    "    Stage 2 objective: Maximize profit given demand scenario and capital endowment.\n",
    "    \"\"\"\n",
    "    profit = 0\n",
    "    for city_index in range(num_cities):\n",
    "        city_demand = demand_scenario[city_index]\n",
    "        city_supply, production_cost = supply(capital, production[city_index], city_index)\n",
    "        revenue = min(city_supply, city_demand) * selling_price_per_unit  # Assume a fixed selling price per unit\n",
    "        profit += revenue - production_cost\n",
    "    return -profit  # Negative because we minimize the function\n",
    "\n",
    "selling_price_per_unit = 2  # Placeholder selling price\n",
    "production_decisions = []\n",
    "\n",
    "# Optimize production for a subset of representative scenarios to illustrate\n",
    "for scenario_index in np.random.choice(range(len(demand)), size=10, replace=False):\n",
    "    demand_scenario = demand[scenario_index]\n",
    "    production_opt = scipy.optimize.minimize(stage2_objective, [1 for _ in range(num_cities)], args=(capital_opt.x, demand_scenario), bounds=[production_bounds]*num_cities)\n",
    "    production_decisions.append(production_opt.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Dataset for QNN\n",
    "Assuming demand has been generated per the previous setup and contains scenarios for each city, the first step is preparing this data for training the QNN. Each city's demand series would serve as a target variable, with relevant features extracted or engineered as necessary (e.g., historical demand, economic indicators, etc.). For simplicity, we'll proceed directly to defining and training a QNN model.\n",
    "\n",
    "Defining the Quantile Neural Network (QNN)\n",
    "The QNN will be structured to predict quantiles of future demand for each city, capturing the uncertainty inherent in these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DemandQNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DemandQNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size)  # Assuming 3 quantiles per city\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Assuming each city's demand can be predicted based on 5 features\n",
    "input_size = 3\n",
    "# Output size: 3 quantiles * num_cities\n",
    "output_size = 3 * num_cities\n",
    "model = DemandQNN(input_size=input_size, output_size=output_size)\n",
    "\n",
    "def quantile_loss(preds, targets, quantiles):\n",
    "    assert len(quantiles) == preds.shape[1], \"Quantiles must match the last dimension of predictions.\"\n",
    "    loss = 0\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = targets - preds[:, i]\n",
    "        loss += torch.max((q-1) * errors, q * errors).mean()\n",
    "    return loss / len(quantiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the QNN\n",
    "The training process involves using historical data to predict future demand quantiles. A custom loss function, such as the pinball loss, is typically used for quantile regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assume quantiles are 25th, 50th, and 75th percentiles\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "num_epochs = 100\n",
    "# Correct input_size based on your features (3 for the three cities in this case)\n",
    "model = DemandQNN(input_size=3, output_size=num_cities * len(quantiles))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Simplifying assumption: use lagged demand as features\n",
    "# # This is a simplification; in practice, you might include more sophisticated features\n",
    "X_demand = demand[:-1]  # Features: demand up to the second-to-last scenario\n",
    "Y_demand = demand[1:]   # Targets: demand from the second scenario onward\n",
    "\n",
    "# # Convert to PyTorch tensors for training the QNN\n",
    "X_train = torch.tensor(X_demand, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_demand, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Ensure your DataLoader is set up as before\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "batch_size = 32  # This can be adjusted based on your system's memory capacity\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, Y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (model and data are already on CPU)\n",
    "        predictions = model(X_batch)\n",
    "        \n",
    "        # Compute loss (ensure your quantile_loss function does not assume GPU computation)\n",
    "        loss = quantile_loss(predictions, Y_batch, quantiles)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    # Optional: Print average loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
